{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUWRCv1Nh5q-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3wI-kiMozv-"
      },
      "source": [
        "Loading the Dataset to Pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cCwfrE3iO4n"
      },
      "outputs": [],
      "source": [
        "# to load the dataset to a pandas dataFrame\n",
        "dataset = pd.read_csv('/content/boston_house_prices.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gzvbVDDpzfE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLYl0K1HiUNe"
      },
      "outputs": [],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBnSlkOEqWBq"
      },
      "source": [
        "Here's How to install kaggle API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vvmz8_3trtZ"
      },
      "outputs": [],
      "source": [
        "# installing the kaggle API\n",
        "!pip install Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh22_C_2uDc5"
      },
      "source": [
        "Importing the EarthQuake Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ghKkImuiWR7"
      },
      "outputs": [],
      "source": [
        "#configuring the kaggle.jason file\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPRHdLODsOOX"
      },
      "outputs": [],
      "source": [
        "\n",
        "#API to fetch the dataset\n",
        "!kaggle competitions download -c LANL-Earthquake-Prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "dataset_1 = '/content/LANL-Earthquake-Prediction.zip'\n",
        "with ZipFile (dataset_1,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print (\"the datasets are extraccted\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2hmzKOQ7sCEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "methods to handle the missing value\n",
        "1. imputation\n",
        "2. Dropping"
      ],
      "metadata": {
        "id": "biQEoLkK5Y_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "NMdaFaSK7hy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the dataset the pandas dataset\n",
        "dataset_3 = pd.read_csv('/content/Placement (1).csv')"
      ],
      "metadata": {
        "id": "iWMv6Og-8BkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "-----------------------------"
      ],
      "metadata": {
        "id": "MTES9SaAIOIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_3.describe()"
      ],
      "metadata": {
        "id": "jq0Gxl75j_-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "-----------------------"
      ],
      "metadata": {
        "id": "fBj2i5Fmj74l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataset_3.shape\n"
      ],
      "metadata": {
        "id": "GyTiTHqEIbJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_3.isnull().sum()"
      ],
      "metadata": {
        "id": "Ms_2iSWEIvJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "central Tendencies\n",
        "1. Mean\n",
        "2. Mode\n",
        "3. Median"
      ],
      "metadata": {
        "id": "hWxVjtZdJZyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#analyze the distribution of data in the salary\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.distplot(dataset_3.salary)"
      ],
      "metadata": {
        "id": "E5Wyg7dcJZXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace Missing value with median value"
      ],
      "metadata": {
        "id": "8Z3nbrF0OTxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_3['salary'].fillna(dataset_3['salary'].median(),inplace=True )\n"
      ],
      "metadata": {
        "id": "bmFVq6SGOQOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_3.head()"
      ],
      "metadata": {
        "id": "XDDus-Mv9g2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_3.isnull().sum()"
      ],
      "metadata": {
        "id": "6nwx9XFWPkPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "filling missing value with mean value"
      ],
      "metadata": {
        "id": "4ORyLBHTP0wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset_3['salary'].fillna(dataset_3['salary'].mean(),inplace=True )"
      ],
      "metadata": {
        "id": "aHcHJml7QSwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_3.isnull().sum()"
      ],
      "metadata": {
        "id": "KwMFiOtHQpFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "filling missing value with mode value"
      ],
      "metadata": {
        "id": "Lr3AnZ4pDBJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset_3['salary'].fillna(dataset_3['salary'].mode(),inplace=True )"
      ],
      "metadata": {
        "id": "iEreIcWWC8mG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping Method"
      ],
      "metadata": {
        "id": "Esj-9n1OABRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_dataset = pd.read_csv('/content/Placement (1).csv')"
      ],
      "metadata": {
        "id": "vjjDyXzKAjKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "salary_dataset.head()"
      ],
      "metadata": {
        "id": "pbN-PC1NBSMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "salary_dataset.shape"
      ],
      "metadata": {
        "id": "vD-B-P4UBYs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "salary_dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "OAZFrqtfAvjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop the missing values\n",
        "salary_dataset = salary_dataset.dropna(how='any')"
      ],
      "metadata": {
        "id": "jUm5rh-XB11T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "salary_dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "xmJTT56LCYRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "salary_dataset.head()"
      ],
      "metadata": {
        "id": "6Khcl3cN-b9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "salary_dataset.shape"
      ],
      "metadata": {
        "id": "l5faBIWECkQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Data Standardarization:\n",
        "\n",
        "The process of standardizing the data to a common format or a common range"
      ],
      "metadata": {
        "id": "bbfbeqsXAzjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn.datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "x7LgjV5MKwDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset =sklearn.datasets.load_breast_cancer()"
      ],
      "metadata": {
        "id": "TgoJ0LwaLaL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_dataset)"
      ],
      "metadata": {
        "id": "UrimPE71Nown"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the data to the pandas dataframe\n",
        "df = pd.DataFrame(new_dataset.data, columns=new_dataset.feature_names)"
      ],
      "metadata": {
        "id": "sm2RL-iIOM_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "kPsRiG2WO5Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "Zp7fEAAyPjQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = df\n",
        "y = new_dataset.target"
      ],
      "metadata": {
        "id": "DV2cewlMPsPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "id": "y_amQ49vZgej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "id": "8UsRiyJ0bAm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "splitting the  data into training data test data"
      ],
      "metadata": {
        "id": "mgxxPJmrbExX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=2)"
      ],
      "metadata": {
        "id": "NnUYDeCUbOS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape, x_train.shape, x_test.shape)"
      ],
      "metadata": {
        "id": "12byMjSGbvij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardize the data"
      ],
      "metadata": {
        "id": "_i-POpUYb45g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_dataset.data.std())"
      ],
      "metadata": {
        "id": "0VfHQGKab8t-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler=StandardScaler()"
      ],
      "metadata": {
        "id": "MoYLtjB1cLnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler.fit(x_train)"
      ],
      "metadata": {
        "id": "8qsRDmXvcJ88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_standardized = scaler. transform(x_train)"
      ],
      "metadata": {
        "id": "C8xlnx6zcbhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train_standardized)"
      ],
      "metadata": {
        "id": "84ucjclUcbdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_standardized = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "pO0_Eqw9cbSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test_standardized)"
      ],
      "metadata": {
        "id": "xyCa8cM9cbD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label Encoding:\n",
        "\n",
        "*   Converting the labels into numeric form.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m4umelqjdc8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the dependecies\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "Cj5kF1Ikdcs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label encoding of breastcancer Dataset"
      ],
      "metadata": {
        "id": "UBrHIZQBeVCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the dataset from csv file to pandas dataframe\n",
        "cancer_dataset = pd.read_csv('/content/breast_cancer_data.csv')"
      ],
      "metadata": {
        "id": "hi8MJYoVeUxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cancer_dataset.head()"
      ],
      "metadata": {
        "id": "oY3ClK8idci7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find the count of different label"
      ],
      "metadata": {
        "id": "SNYGzYiQfcuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cancer_dataset['diagnosis'].value_counts()"
      ],
      "metadata": {
        "id": "DPnnKcXrfXlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the label Encoder function\n",
        "Label_encode = LabelEncoder()\n"
      ],
      "metadata": {
        "id": "GFW2ijJifcAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "labels = Label_encode.fit_transform(cancer_dataset.diagnosis)"
      ],
      "metadata": {
        "id": "C7FAh7H7hxxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#appending the label to the dataframe\n",
        "cancer_dataset['target'] = labels"
      ],
      "metadata": {
        "id": "tCivlHidfWhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cancer_dataset.head()"
      ],
      "metadata": {
        "id": "KtSouuWsfWd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0-->Benign\n",
        "\n",
        "1-->Malignant\n"
      ],
      "metadata": {
        "id": "05mVb3XPiMU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cancer_dataset['target'].value_counts()"
      ],
      "metadata": {
        "id": "1aIj_meqfWZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label encoding of iris Dataset"
      ],
      "metadata": {
        "id": "5ImoG19d2Pp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the dataset from csv file to pandas dataframe\n",
        "iris_dataset = pd.read_csv('/content/iris_data.csv')"
      ],
      "metadata": {
        "id": "R1au-PIyfWPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_dataset.head()"
      ],
      "metadata": {
        "id": "3XQMh9lp2-YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#find the count of different label\n",
        "iris_dataset['Species'].value_counts()"
      ],
      "metadata": {
        "id": "V_ZCUkOk2-TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the label encoder function\n",
        "label_encode = LabelEncoder()"
      ],
      "metadata": {
        "id": "5Wf7cbNW2-PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_1 = label_encode.fit_transform(iris_dataset.Species)"
      ],
      "metadata": {
        "id": "3yRSTXp-2-LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# appending the labels to the dataframe\n",
        "iris_dataset['target']=labels_1"
      ],
      "metadata": {
        "id": "IdDG_O1D2-Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_dataset.head()"
      ],
      "metadata": {
        "id": "R5EDKnve2970"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_dataset.tail()"
      ],
      "metadata": {
        "id": "iMF3zur548Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0-->iris-setosa\n",
        "\n",
        "1-->iris-vericolor\n",
        "\n",
        "2-->iris-virginica"
      ],
      "metadata": {
        "id": "av5Y5Wa12O7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris_dataset['target'].value_counts()"
      ],
      "metadata": {
        "id": "OJ2vSuHt5Plc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train_Test_split in machine learning"
      ],
      "metadata": {
        "id": "dEZ_P4Xrx4vW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "aqOIlGzV5Ywj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data collection analysis\n",
        "\n",
        "PIMA diabetes Dataset"
      ],
      "metadata": {
        "id": "nDjRYv08hvfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the diabetes to a pandas dataframe\n",
        "diabetes_dataset =pd.read_csv('/content/diabetes.csv')"
      ],
      "metadata": {
        "id": "ByHNyXFThPmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_dataset.head()"
      ],
      "metadata": {
        "id": "WGujIiLtillM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_dataset.shape"
      ],
      "metadata": {
        "id": "ORjekB_Riq_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GETTING THE STATISTICAL MEASURES OF DATA\n",
        "diabetes_dataset.describe()"
      ],
      "metadata": {
        "id": "0BzYDDnri1gE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_dataset['Outcome'].value_counts()"
      ],
      "metadata": {
        "id": "yzeRQbMSjJrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0--> Non-diabetes\n",
        "\n",
        "1--> Diabetes"
      ],
      "metadata": {
        "id": "_mgw-xf08Ti4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_dataset.groupby('Outcome').mean()"
      ],
      "metadata": {
        "id": "MM9XYSsZ8Ekf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separating the data and labels\n",
        "x = diabetes_dataset.drop(columns='Outcome', axis=1)"
      ],
      "metadata": {
        "id": "RwgzqkuF8nSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = diabetes_dataset['Outcome']"
      ],
      "metadata": {
        "id": "bLvVdLRR8y12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "id": "Qp828ioe9ZZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "id": "r1ubUVJ59cy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Standardization"
      ],
      "metadata": {
        "id": "oWiJ19OV9qhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler( )"
      ],
      "metadata": {
        "id": "nlqdL1qG9mEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler.fit(x)"
      ],
      "metadata": {
        "id": "NNKuJ3cz97iH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "standardized_data = scaler.transform(x)"
      ],
      "metadata": {
        "id": "DioJVEb2-DJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(standardized_data)"
      ],
      "metadata": {
        "id": "1Gb5JGac-O2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = standardized_data\n",
        "y = diabetes_dataset['Outcome']"
      ],
      "metadata": {
        "id": "NpDi8oVA-aqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "qOhZZNjw_E6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SPLITTING THE DATA INTO TRANNING DATA AND TESTING DATA"
      ],
      "metadata": {
        "id": "kEkemxQUnVBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=2)"
      ],
      "metadata": {
        "id": "x_utfqVK_J6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train, x_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "AZwuVCLfoEc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling Imbalaced dataset\n",
        "\n",
        "Imbalanced Dataset\n",
        ":A dataset with unequal class distribution"
      ],
      "metadata": {
        "id": "8IVM4TJZoXKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "s_59LpAhoVeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the dataset to the pandas dataframe\n",
        "credit_card_dataset =pd.read_csv('/content/credit_data.csv')"
      ],
      "metadata": {
        "id": "mo6rVDe6oVRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credit_card_dataset.head()"
      ],
      "metadata": {
        "id": "guzfJM7ToU6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credit_card_dataset.tail()"
      ],
      "metadata": {
        "id": "QXq1OSACs9xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#disribution of the two classes\n",
        "credit_card_dataset['Class'].value_counts()"
      ],
      "metadata": {
        "id": "dn6Ytskixmfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is highly imalanced dataset"
      ],
      "metadata": {
        "id": "q64P3vADy5Tg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0--> legit transaction\n",
        "\n",
        "1--> fraudulent transaction\n"
      ],
      "metadata": {
        "id": "Wu6B78oBzDi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#separating the legit and fraudlunet transaction"
      ],
      "metadata": {
        "id": "KvhBbG2GyFCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "legit = credit_card_dataset[credit_card_dataset.Class==0]"
      ],
      "metadata": {
        "id": "3dGoDMoXy4LR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fraud = credit_card_dataset[credit_card_dataset.Class==1]"
      ],
      "metadata": {
        "id": "EDYZr85U1ZRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(legit.shape)\n",
        "print(fraud.shape)"
      ],
      "metadata": {
        "id": "dPiw8qBg1ZM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Under-Sampling\n",
        "\n",
        "build a sample dataset containing similar distribution of legit & fraudulent tranction"
      ],
      "metadata": {
        "id": "gDaxvV6a17rH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of Fraudulent transaction"
      ],
      "metadata": {
        "id": "Ap38eNC62b_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "legit_sample = legit.sample(n=492)"
      ],
      "metadata": {
        "id": "nDOe_YZ-1ZH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(legit_sample)"
      ],
      "metadata": {
        "id": "9a147w4c1Y9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concatenate the two DataFrame"
      ],
      "metadata": {
        "id": "PfzVzJme26ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset =pd.concat([legit_sample, fraud], axis=0)"
      ],
      "metadata": {
        "id": "lviKdwTY255o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset.head()"
      ],
      "metadata": {
        "id": "Zyoc4sBI3S-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset.tail()"
      ],
      "metadata": {
        "id": "eiyC1DEY3S6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset['Class'].value_counts()"
      ],
      "metadata": {
        "id": "RI3I30ea3S2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FEATURES EXTRACTION OF TEXT DATA: Tf-Idf VECTORIZER"
      ],
      "metadata": {
        "id": "0HbB7N8_3toH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n"
      ],
      "metadata": {
        "id": "nqz_HSyq3Sx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "sJZr_9eT3SuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the stopword in english\n",
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "uwrH0R9B3Sqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing\n"
      ],
      "metadata": {
        "id": "DtnSUs4g6Sr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the dataset tha pandas dataframe\n",
        "news_dataset = pd.read_csv('/content/fake_news_dataset.csv')"
      ],
      "metadata": {
        "id": "2qIxSK1x3SmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_dataset.shape"
      ],
      "metadata": {
        "id": "efjD6HL-3Shz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_dataset.head()"
      ],
      "metadata": {
        "id": "8CwMYto53Sdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#counting the number of missing values in dataset\n",
        "news_dataset.isnull().sum"
      ],
      "metadata": {
        "id": "0iw14aac7LEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#replacing the null value with empty string\n",
        "news_dataset = news_dataset.fillna('')"
      ],
      "metadata": {
        "id": "85NrjRCu3SZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merging the author name and news title\n",
        "news_dataset['content'] = news_dataset['author']+ '' + news_dataset['title']"
      ],
      "metadata": {
        "id": "fFuZ_xB73SQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(news_dataset['content'])"
      ],
      "metadata": {
        "id": "PRSJBw0M3SK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# separating the data and label\n",
        "x = news_dataset.drop(columns=['label'],axis=1)"
      ],
      "metadata": {
        "id": "yzT0-kGb3SE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y= news_dataset['label']"
      ],
      "metadata": {
        "id": "db8Gtn8B_ZJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "Bz7vXrwn_rjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming:\n",
        "\n",
        "stemming is the process of reducing a word to its root word\n",
        "\n",
        "examples: actors,  actress, acting --> act"
      ],
      "metadata": {
        "id": "KO_CekASFHiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "port_stem =PorterStemmer()"
      ],
      "metadata": {
        "id": "qSkNsceiFG0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stemming(content):\n",
        "  stemmed_content = re.sub('[^a-zA-Z]','', content)\n",
        "  stemmed_content = stemmed_content.lower()\n",
        "  stemmed_content = stemmed_content.split()\n",
        "  stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
        "  stemmed_content =''.join(stemmed_content)\n",
        "  return stemmed_content"
      ],
      "metadata": {
        "id": "b7d5na_A_xDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_dataset['content'] = news_dataset['content'].apply(stemming)"
      ],
      "metadata": {
        "id": "_Yc5b1IQHuKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(news_dataset['content'])"
      ],
      "metadata": {
        "id": "6-0ML34xIQpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#separting the data and label\n",
        "x= news_dataset['content'].values\n",
        "y= news_dataset['content'].values"
      ],
      "metadata": {
        "id": "4eXjxqcXJHdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "id": "tik-Bou6JZj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "id": "_bW9rHGoJh3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape\n"
      ],
      "metadata": {
        "id": "ff_w5yw-JjUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numerical dataset preprocessing - use case"
      ],
      "metadata": {
        "id": "1G-5UdtzGbgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Fc_BN9CiGsWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data collection and preprocessing\n"
      ],
      "metadata": {
        "id": "i0fWV2_1Hcwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the dataset from csv file to pandas dataframe\n",
        "diabetes_dataset = pd.read_csv('/content/diabetes.csv')"
      ],
      "metadata": {
        "id": "nvzHOjATHKEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read first 5 rows of the dataset\n",
        "diabetes_dataset.head()"
      ],
      "metadata": {
        "id": "PVTvsHM6H4dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# No. of rows and Column in the dataset\n",
        "diabetes_dataset.shape"
      ],
      "metadata": {
        "id": "Rd3p6VHEIDNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# More information of dataset\n",
        "diabetes_dataset.describe()"
      ],
      "metadata": {
        "id": "PoK-8u-vIQhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SEparating features and target"
      ],
      "metadata": {
        "id": "xYkca7-CI3C1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x= diabetes_dataset.drop(columns='Outcome', axis=1)\n",
        "y= diabetes_dataset['Outcome']"
      ],
      "metadata": {
        "id": "foxBWuo5Iobl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "id": "Iml5zSqHJP82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "id": "CeXk9zAgJxGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0--> Non-diabetic\n",
        "\n",
        "1--> Diabetic\n"
      ],
      "metadata": {
        "id": "xLymQxg7KAxD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Standardization"
      ],
      "metadata": {
        "id": "0llGxYX0KNwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler= StandardScaler()"
      ],
      "metadata": {
        "id": "IJEK8O1zJ0AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "standardized_data= scaler.fit_transform(x)"
      ],
      "metadata": {
        "id": "m1TCUwEjKZ_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x= standardized_data"
      ],
      "metadata": {
        "id": "Env1alfTKmlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "id": "qr5uIuX1KuaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "id": "fz7aVeMdKwrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the datasetinto Traning data and Testng data"
      ],
      "metadata": {
        "id": "V4G5cqy2K1M9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test =train_test_split(x, y, test_size=0.2, random_state=2)"
      ],
      "metadata": {
        "id": "Pn2bAZozKzHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape, x_train.shape, x_test.shape)"
      ],
      "metadata": {
        "id": "X-Eq-SKCLaJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Data preprocessing - use case"
      ],
      "metadata": {
        "id": "t6uEOX4HpD_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "OXZvOhmzLuUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "zS_WKRx41-7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing stopwords\n",
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "01jEGPDX2Foa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Pre-processing"
      ],
      "metadata": {
        "id": "BUsAw2Jr2hDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the dataset to the pandas dataFrame\n",
        "news_dataset = pd.read_csv('/content/fake_news_dataset.csv')"
      ],
      "metadata": {
        "id": "FjU1gKeL2WHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reading 5 rowss of dataset to the pandas dataFrame\n",
        "news_dataset.head()"
      ],
      "metadata": {
        "id": "z_bTxNYE2_47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0--> REAL NEWS\n",
        "\n",
        "1-->FAKE NEWS"
      ],
      "metadata": {
        "id": "JfPnFt-V44LV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "news_dataset.shape"
      ],
      "metadata": {
        "id": "nZpzCUM_40xN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the missing values\n",
        "news_dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "E1Meuj-85Qn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#replacing the missing values with null string\n",
        "newss_dataset = news_dataset.fillna('')"
      ],
      "metadata": {
        "id": "oDcZSiMJ5gpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merging the author name and news title\n",
        "news_dataset['content'] =news_dataset['author']+''+news_dataset['title']"
      ],
      "metadata": {
        "id": "Y-tCPBEa52jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_dataset.head()"
      ],
      "metadata": {
        "id": "JB9lJVMY6XWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#separating the feature and Target\n",
        "x=news_dataset.drop(columns= 'label', axis=1)\n",
        "y=news_dataset['label']"
      ],
      "metadata": {
        "id": "QZVnFLTc6dB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "id": "7y-8puk2-snZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "id": "c-35_kjC-yIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEMMIMG:\n",
        "\n",
        "Stemming is the processes of reducing a word to its root word."
      ],
      "metadata": {
        "id": "RfO1E41O-3qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "port_stem =PorterStemmer()"
      ],
      "metadata": {
        "id": "Kkc7_FjQ-3cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Stem(content):\n",
        "  stemmed_content = re.sub('[a-zA-Z]',' ',str(content))\n",
        "  stemmed_content = stemmed_content.lower()\n",
        "  stemmed_content = stemmed_content.split()\n",
        "  stemmed_content =[port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
        "  stemmed_content = ' '.join(stemmed_content)\n",
        "  return stemmed_content"
      ],
      "metadata": {
        "id": "jDdEYeBJ-1KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_dataset['content'] =news_dataset['content'].apply(Stem)"
      ],
      "metadata": {
        "id": "etla3bEFCoqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(news_dataset['content'])"
      ],
      "metadata": {
        "id": "O5S72UEMEleE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x= news_dataset['content'].values\n",
        "y= news_dataset['label'].values"
      ],
      "metadata": {
        "id": "V6PwZJiFSwRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "id": "taVbndAETOxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "id": "9jKOyVIcTUmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "CRS0deZ-TY7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the textual data to features vector\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(x)\n",
        "x= vectorizer.transform(x)"
      ],
      "metadata": {
        "id": "4lBcunWpTc9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "id": "mXirgNR3T2or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nSxPG09kWIai"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}